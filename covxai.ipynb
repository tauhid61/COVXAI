{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\ntry:\n    os.makedirs('../outputs')\nexcept Exception as e:\n    print(f'Directory Exists!')\nlogdir = r'/kaggle/outputs/'\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:18.599278Z","iopub.execute_input":"2022-04-05T11:05:18.600007Z","iopub.status.idle":"2022-04-05T11:05:18.62747Z","shell.execute_reply.started":"2022-04-05T11:05:18.599918Z","shell.execute_reply":"2022-04-05T11:05:18.626598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install randaugment\n# # %cd c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages \n# from randaugment import RandAugment\n# # %cd C:\\XAI","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:19.227061Z","iopub.execute_input":"2022-04-05T11:05:19.227366Z","iopub.status.idle":"2022-04-05T11:05:19.251062Z","shell.execute_reply.started":"2022-04-05T11:05:19.227331Z","shell.execute_reply":"2022-04-05T11:05:19.250237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:19.478895Z","iopub.execute_input":"2022-04-05T11:05:19.479478Z","iopub.status.idle":"2022-04-05T11:05:28.734942Z","shell.execute_reply.started":"2022-04-05T11:05:19.479435Z","shell.execute_reply":"2022-04-05T11:05:28.734084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nlogdir = r'/kaggle/outputs/'\nimport torch\nimport PIL \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport torch.nn.functional as F \nimport warnings,copy, random, time, glob, math, torch, argparse\nfrom torch import nn,optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom IPython.display import FileLink\nfrom zipfile import ZipFile\nfrom pathlib import Path\nimport splitfolders\nwriter = SummaryWriter(log_dir=logdir, flush_secs=10)\ntorch.manual_seed(3407)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:28.738237Z","iopub.execute_input":"2022-04-05T11:05:28.73846Z","iopub.status.idle":"2022-04-05T11:05:35.143817Z","shell.execute_reply.started":"2022-04-05T11:05:28.738431Z","shell.execute_reply":"2022-04-05T11:05:35.143054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_from_checkpoint(PATH):\n    checkpoint = torch.load(PATH)\n    last_epoch = checkpoint['epoch']\n    model = checkpoint['model']\n    optimizer = checkpoint['optimizer']\n    best_test_acc = checkpoint['acc']\n    last_lr = checkpoint['last_lr']\n    return model, optimizer, last_epoch, best_test_acc, last_lr\ndef save_to_checkpoint(epoch, model, optimizer, test_acc, last_lr, PATH):\n    torch.save({'epoch': epoch, 'model': model,'optimizer': optimizer,'acc': test_acc, 'last_lr': last_lr}, PATH)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:35.145542Z","iopub.execute_input":"2022-04-05T11:05:35.145785Z","iopub.status.idle":"2022-04-05T11:05:35.152637Z","shell.execute_reply.started":"2022-04-05T11:05:35.145751Z","shell.execute_reply":"2022-04-05T11:05:35.151813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def PrintImagefromDataloader(iterator, i):\n    dataiter = iter(iterator)\n    images, labels = dataiter.next()\n    plt.imshow(np.transpose(images[i].cpu().detach().numpy(), (1, 2, 0)))\n    plt.show()\ndef GetImage(iterator):\n#     warnings.filterwarnings(\"ignore\", category=UserWarning) \n    samples = iter(iterator)\n    data, label = samples.next()\n    return data\ndef plot_graph(paramlist, picname):\n    plt.figure(figsize=(12,3))\n    plt.plot(paramlist)\n    plt.title(label=f'Best Acc : {max(paramlist)*100}%')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.savefig(picname, dpi=300, bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:35.155061Z","iopub.execute_input":"2022-04-05T11:05:35.155305Z","iopub.status.idle":"2022-04-05T11:05:35.165559Z","shell.execute_reply.started":"2022-04-05T11:05:35.155272Z","shell.execute_reply":"2022-04-05T11:05:35.164807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_acc(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim = True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() / y.shape[0]\n    return acc\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\ndef train_one_epoch(model, iterator, optimizer, criterion, device):\n    epoch_loss = 0\n    epoch_acc = 0\n    model.train()\n    for i, (x, y) in enumerate(iterator):\n        x = x.to(device, non_blocking=True)\n        if isinstance(y, (tuple, list)):\n            y1, y2, lam = y\n            y = (y1.to(device, non_blocking=True), y2.to(device, non_blocking=True), lam)\n        else:\n            y = y.to(device, non_blocking=True)\n        optimizer.zero_grad() \n        y_pred = model(x) \n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        # Old - >\n        acc = calc_acc(y_pred, y)\n        # acc = cutmix_calc_acc(outputs=y_pred, targets=y, data=x) #review\n        epoch_loss += loss.item()\n        epoch_acc += acc #check  \n    return epoch_loss / len(iterator), epoch_acc / len(iterator), optimizer.param_groups[0][\"lr\"]\ndef test_one_epoch(model, iterator, criterion, device):\n    epoch_loss = 0\n    epoch_acc = 0\n    model.eval()\n    with torch.no_grad():\n        for i, (x, y) in enumerate(iterator):\n            x = x.to(device, non_blocking=True)\n            y = y.to(device, non_blocking=True)\n            y_pred= model(x)\n            loss = criterion(y_pred, y)\n            acc = calc_acc(y_pred=y_pred, y=y)\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()  \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\ndef train_loop(last_epoch, epochs, best_test_acc, model, trainiterator, testiterator, traincriteron, \n               testcriteron, optimizer, \n#                scheduler, \n               device, SAVEPATH):\n    history, logs = [[], [], [], []], []\n    \n    for epoch in range(last_epoch+1, last_epoch+epochs+1):\n#         warnings.filterwarnings(\"ignore\", category=UserWarning)\n        start_time = time.monotonic()\n        train_loss, train_acc, last_lr = train_one_epoch(model=model, iterator=trainiterator, criterion=traincriteron, \n                                                    optimizer=optimizer, device=device)\n        test_loss, test_acc = test_one_epoch(model=model, iterator=testiterator, criterion=testcriteron, device=device)\n#         scheduler.step()\n        end_time = time.monotonic()\n        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n        \n        log = f'Epoch: {epoch:04d} ({epoch_mins}m {epoch_secs}s) | Train Loss: {train_loss:.5f}, Test Loss: {test_loss:.5f} | Train Acc: {train_acc*100:.5f}, Test Acc: {test_acc*100:.5f}'\n        print(log)\n#         print(f'Epoch: {epoch:04d} ({epoch_mins}m {epoch_secs}s), lr = {optimizer.param_groups[0][\"lr\"]} | Train Loss: {train_loss:.5f}, Test Loss: {test_loss:.5f} | Train Acc: {train_acc*100:.5f}, Test Acc: {test_acc*100:.5f}')\n        \n        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n        writer.add_scalar(\"Acc/train\", train_acc, epoch)\n        writer.add_scalar(\"Loss/Valid\", test_loss, epoch)\n        writer.add_scalar(\"Acc/Valid\", test_acc, epoch)\n        history[0].append(train_loss) \n        history[1].append(train_acc)\n        history[2].append(test_loss)\n        history[3].append(test_acc)\n        logs.append(log)\n        if test_acc>best_test_acc:\n            best_test_acc = test_acc\n            save_to_checkpoint(epoch=epoch, model=model, optimizer=optimizer, test_acc=test_acc, PATH=SAVEPATH, last_lr=last_lr)\n    return history, logs","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:05:35.166817Z","iopub.execute_input":"2022-04-05T11:05:35.167566Z","iopub.status.idle":"2022-04-05T11:05:35.190475Z","shell.execute_reply.started":"2022-04-05T11:05:35.167517Z","shell.execute_reply":"2022-04-05T11:05:35.189827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_linlayer_idx(model):\n    offset = len(model._modules['features']) + len([model._modules['avgpool']]) # for 1 avgpool layer\n    indices = [] \n    for i, layer in enumerate(model._modules['classifier']):\n        if isinstance(layer, nn.Linear):\n            indices.append(offset+i)\n    return indices\ndef linear_to_conv(layers):\n    newlayers = [] \n    for i, layer in enumerate(layers):\n        if isinstance(layer, nn.Linear):\n            newlayer = None\n            # layer -> [m, n, k, k], weight -> [n, m, k, k] \n            kernel_size = 7 if i==0 else 1\n            m, n = layer.weight.shape[1]//(kernel_size**2), layer.weight.shape[0]\n            newlayer = nn.Conv2d(in_channels=m, out_channels=n, kernel_size=kernel_size) \n            newlayer.weight = nn.Parameter(data=layer.weight.reshape(n, m, kernel_size, kernel_size))\n            newlayer.bias = nn.Parameter(layer.bias)\n            newlayers += [newlayer]\n        else:\n            newlayers += [layer]\n    return newlayers\ndef newlayer(layer, func):\n    layer = copy.deepcopy(layer)\n    try:\n        layer.weight = torch.nn.Parameter(func(layer.weight))\n    except AttributeError:\n        pass\n    try:\n        layer.bias = torch.nn.Parameter(func(layer.bias))\n    except AttributeError:\n        pass\n    return layer\ndef get_rho_incr(n):\n    if n>=31:\n        rho = lambda p : p \n        incr = lambda z : z+1e-9\n    elif 17<=n<=30:\n        rho = lambda p : p \n        # z : z + 1e-9 + gamma*root(mean(z^2)) ;;; rms(z)\n        incr = lambda z : z+1e-9+0.25*((z**2).mean()**.5).data  \n    elif n<=16:\n        # gamma=0.25 ; p : p (1+gamma)\n        # weight tensor is clamped to get only positive val\n        rho = lambda p : p + 0.25*p.clamp(min=0) \n        incr = lambda z : z+1e-9  \n    return rho, incr\ndef apply_lrp(model, image):\n        # Step 1 -> \n        image = torch.unsqueeze(image, dim=0)\n        layers = list(model._modules['features']) + [model._modules['avgpool']] + linear_to_conv(list(model._modules['classifier']))\n        linlayer_indices = get_linlayer_idx(model)\n        n = len(layers) \n        activations = [image] + [None]*n \n        \n        # Step 2 ->\n        for i in range(n):\n#                 print(f'{i}, {layers[i]}')\n                if i in linlayer_indices and i==32:\n                        activations[i] = activations[i].reshape((1, 512, 7, 7))\n                activation = layers[i].forward(activations[i])\n                if isinstance(layers[i], torch.nn.modules.pooling.AdaptiveAvgPool2d):\n                        activation = torch.flatten(activation, start_dim=1)\n                activations[i+1] = activation\n                \n        # Step 3 ->\n        one_hot_out = []\n        output_activation = activations[-1].detach().cpu().numpy()\n        maxval = output_activation.max()\n        for val in output_activation[0]:\n#                 print(val)\n                if val==maxval:\n                        one_hot_out.append(val)\n                else:\n                        one_hot_out.append(0.0)\n        try:\n            activations[-1] = torch.FloatTensor([one_hot_out]).to(device)\n        except TypeError: \n            pass    \n        # Step 4 ->\n        relevances = [None]*n + [activations[-1]]\n        for i in range(0, n)[::-1]:\n                curr_layer = layers[i]\n#                 print(f'{i}, {curr_layer}')\n                if isinstance(curr_layer, torch.nn.MaxPool2d):\n                        layers[i] = torch.nn.AvgPool2d(kernel_size=2)\n                        curr_layer = layers[i]\n                if isinstance(curr_layer, torch.nn.Conv2d) or isinstance(curr_layer, torch.nn.AvgPool2d) or isinstance(curr_layer, torch.nn.Linear):\n                        activations[i] = activations[i].data.requires_grad_(True)\n                        rho_func, incr_func = get_rho_incr(i)\n                        # Step 1\n                        z = incr_func(newlayer(layer=layers[i], func=rho_func).forward(activations[i]))\n                        # Step 2\n                        s = (relevances[i+1]/z)\n                        # Step 3\n                        (z*s.data).sum().backward() ;\n                        c = activations[i].grad\n                        # Step 4\n                        relevances[i] = (activations[i]*c).data \n                else:\n                        relevances[i] = relevances[i+1]\n        return relevances[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:06:14.43539Z","iopub.execute_input":"2022-04-05T11:06:14.435666Z","iopub.status.idle":"2022-04-05T11:06:14.459122Z","shell.execute_reply.started":"2022-04-05T11:06:14.435636Z","shell.execute_reply":"2022-04-05T11:06:14.458401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datadir  = '../input/sarscov2-ctscan-dataset'\nsplitfolders.ratio(datadir, output=\"output\", seed=1337, ratio=(.8, 0.2)) ","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:06:17.206068Z","iopub.execute_input":"2022-04-05T11:06:17.206543Z","iopub.status.idle":"2022-04-05T11:06:28.401773Z","shell.execute_reply.started":"2022-04-05T11:06:17.206507Z","shell.execute_reply":"2022-04-05T11:06:28.401062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\n# %% Load data\n\n\nTRAIN_ROOT = \"./output/train\"\nTEST_ROOT = \"./output/val\"\ntrain_data = datasets.ImageFolder(root=TRAIN_ROOT)\ntest_data = datasets.ImageFolder(root=TRAIN_ROOT)\n\n# %% Prepare data for pretrained model\n# transforms = transforms.Compose([transforms.Resize((255,255)), transforms.ToTensor()])\ntrain_transforms = transforms.Compose([transforms.Resize((256, 256)),\n                                       transforms.RandomRotation(degrees=(-20, +20)),              \n                                       transforms.CenterCrop(size=224), \n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(), \n#                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                       ])\ntest_transforms = transforms.Compose([transforms.Resize((224, 224)),\n                                      transforms.ToTensor(),\n#                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                      ])\n\n\ntrain_dataset = datasets.ImageFolder(root=TRAIN_ROOT, transform=train_transforms)\ntest_dataset = datasets.ImageFolder(root=TEST_ROOT, transform=test_transforms)\n\n#train_dataset[0][0].permute(1,2,0)\n# %% Create data loaders\nbatch_size = 128\ntrainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntestloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n\nprint(f'Image shape = [{GetImage(trainloader).shape}]')\nprint(f'Classes : {train_data.classes}')\nprint(f'Image from Trainloader')\nPrintImagefromDataloader(trainloader, i=0)\nprint(f'Image from Testloader')\nPrintImagefromDataloader(testloader, i=0)   ","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:51:32.000472Z","iopub.execute_input":"2022-04-05T11:51:32.00074Z","iopub.status.idle":"2022-04-05T11:51:39.853399Z","shell.execute_reply.started":"2022-04-05T11:51:32.000711Z","shell.execute_reply":"2022-04-05T11:51:39.852289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 60\ndatasetname = f'covid-ctscan'\nmodelname = f'vgg16'\nSAVEPATH = f\"/kaggle/outputs/{datasetname}-{modelname}.pt\"\nlast_epoch, best_test_acc = 0, 0.0\nnum_classes = len(train_data.classes)\nmodel = models.vgg16(pretrained=True)\nmodel.classifier[6].out_features = num_classes\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\ncriterion = nn.CrossEntropyLoss()\nhist, logs = train_loop(last_epoch=last_epoch, epochs=EPOCHS, best_test_acc=best_test_acc, model=model, \n                        trainiterator=trainloader, testiterator=testloader,\n                        traincriteron=criterion, testcriteron=criterion, \n                        optimizer=optimizer, device=device, SAVEPATH=SAVEPATH)\nwriter.flush()\n# train_losses, train_accs, test_losses, test_accs = hist[0], hist[1], hist[2], hist[3]transforms","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:10:30.98036Z","iopub.execute_input":"2022-04-05T11:10:30.980765Z","iopub.status.idle":"2022-04-05T11:33:02.749815Z","shell.execute_reply.started":"2022-04-05T11:10:30.980715Z","shell.execute_reply":"2022-04-05T11:33:02.748994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/outputs\npicname = f'{datasetname}-{modelname}-({last_epoch+1}-{last_epoch+EPOCHS})-acc-{int(max(hist[3])*100000)}.jpg'\nplot_graph(hist[3], picname)\nwith open(\"train_losses.txt\", \"w\") as output:\n    output.write(str(hist[0]))\nwith open(\"train_accs.txt\", \"w\") as output:\n    output.write(str(hist[1]))\nwith open(\"test_losses.txt\", \"w\") as output:\n    output.write(str(hist[2]))\nwith open(\"test_accs.txt\", \"w\") as output:\n    output.write(str(hist[3]))\nwith open(\"logs.txt\", \"w\") as output:\n    output.write(str(logs))\n%cd /kaggle/working\nzipname = f'{datasetname}-{modelname}-({last_epoch+1}-{last_epoch+EPOCHS})-acc-{int(max(hist[3])*100000)}.zip'\nwith ZipFile(zipname, 'w') as zipf:\n    for name in glob.glob('/kaggle/outputs/*'):\n        zipf.write(name)\ndisplay(FileLink(zipname))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:34:19.863223Z","iopub.execute_input":"2022-04-05T11:34:19.863501Z","iopub.status.idle":"2022-04-05T11:34:25.533575Z","shell.execute_reply.started":"2022-04-05T11:34:19.863471Z","shell.execute_reply":"2022-04-05T11:34:25.532825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = cv2.imread('castle.jpg')\n# img = np.array(img)[..., ::-1] ## rotating axis -> rgb to bgr \n# img = img/255 # Shape : [224, 224, 3]\n# # img = img[np.newaxis] ## Adds a dimension; Shape: [224, 224, 3] -> [1, 224, 224, 3]\n# img = img.transpose([2, 0, 1]) ## Shape: [1, 224, 224, 3] -> [1, 3, 224, 224]\n# img.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs, labels = next(iter(testloader))\ninputs = inputs.to(device)\nlabels = labels.numpy()\noutputs = model(inputs).max(1).indices.detach().cpu().numpy()\ncomparison = pd.DataFrame()\nprint(\"Batch accuracy: \", (labels==outputs).sum()/len(labels))\ncomparison[\"labels\"] = labels\ncomparison[\"outputs\"] = outputs\nprint(comparison)\n# len(inputs[:])\nfor i in range(127):\n    pred_lebel = None\n    classes = ['COVID', 'non-COVID']\n#     print(f'{i}, {classes[labels[i]]}')\n#     plt.imshow(inputs[i].permute(1,2,0).detach().cpu().numpy())\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T11:53:20.749517Z","iopub.execute_input":"2022-04-05T11:53:20.749801Z","iopub.status.idle":"2022-04-05T11:53:24.314666Z","shell.execute_reply.started":"2022-04-05T11:53:20.74977Z","shell.execute_reply":"2022-04-05T11:53:24.313019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # visualize steps\n# n= len(layers)\n# acts = [torch.tensor(2)] + [None]*n\n# print(acts)\n# acts_last = torch.tensor([1, 2, 3, 4, 5])\n# out = acts_last.detach().cpu().numpy()\n# onehot_out = []\n# for i in out:\n#     if i == out.max():\n#         onehot_out.append(i)\n#     else:\n#         onehot_out.append(0)\n# acts_last = torch.FloatTensor([onehot_out])\n# print()\n# print(acts_last)\n# print()\n# rel = [None]*n + [acts_last]\n# print(rel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%\n# Calculate relevances for first image in this test batch\nfor i in range(0, 20):\n    image_relevances = apply_lrp(model, inputs[i])\n    image_relevances = image_relevances.permute(0,2,3,1).detach().cpu().numpy()[0]\n    image_relevances = np.interp(image_relevances, (image_relevances.min(),image_relevances.max()), (0, 1))\n    # Show relevances\n    pred_label = list(test_dataset.class_to_idx.keys())[list(test_dataset.class_to_idx.values()).index(labels[i])]\n\n    if outputs[i] == labels[i]:\n        print(\"Groundtruth for this image: \", pred_label)\n        # Plot images next to each other\n        plt.axis('off')\n        plt.suptitle(f'Image[{i}], label={pred_label}')\n        plt.subplot(1,2,1)\n        plt.imshow(image_relevances[:,:,0], cmap=\"seismic\")\n        plt.subplot(1,2,2)\n        plt.imshow(inputs[i].permute(1,2,0).detach().cpu().numpy())\n        plt.savefig(f'Covid-CTscan Image[{i}], label={pred_label}.jpg', dpi=500)\n        plt.show()\n    else:\n        print(\"This image is not classified correctly.\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T12:02:55.836388Z","iopub.execute_input":"2022-04-05T12:02:55.83666Z","iopub.status.idle":"2022-04-05T12:03:33.06009Z","shell.execute_reply.started":"2022-04-05T12:02:55.836628Z","shell.execute_reply":"2022-04-05T12:03:33.059321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}